{"cells":[{"cell_type":"markdown","metadata":{"id":"CfmoV8NvgcH6"},"source":["# Preparación"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2vq0D32gLN6"},"outputs":[],"source":["pip install --upgrade scikit-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1N6E7SVFa99Q"},"outputs":[],"source":["pip install scikit-tda"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Y3LU_Tyn56y"},"outputs":[],"source":["pip install gudhi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3n0rJDNbgaU"},"outputs":[],"source":["import time\n","import warnings\n","from ripser import ripser\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from persim import plot_diagrams\n","import persim\n","import glob\n","from numpy import asarray\n","from PIL import Image\n","import os\n","import csv\n","\n","from sklearn.utils import shuffle\n","from sklearn import cluster, datasets\n","from sklearn.preprocessing import StandardScaler\n","from itertools import cycle, islice\n","import random\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.preprocessing import StandardScaler\n","\n","from sklearn.semi_supervised import LabelPropagation\n","from sklearn.semi_supervised import LabelSpreading\n","from sklearn.semi_supervised import SelfTrainingClassifier\n","from sklearn.svm import SVC\n","import warnings\n","\n","import pandas as pd\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BKUy5wYyQeXf"},"outputs":[],"source":["!wget https://unirioja-my.sharepoint.com/:x:/g/personal/adines_unirioja_es/EVb0cuOzAMNAmzMx9_U9EfEBj9ZSpd9vdPsA_hepzC5NqQ?download=1 -O bci.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YaKUIPXXQeXj"},"outputs":[],"source":["def load_prima():\n","  df=pd.read_csv(\"bci.csv\", sep=',',header=None)\n","  df1 = df.iloc[:,:-1]\n","  df2=df.iloc[:,-1]\n","  return df1.values,df2.values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95xqhAzN9Lqs"},"outputs":[],"source":["def preparar_dataset(data,target,n_labeled=15, fold=0):\n","  numFolds=5\n","  scaler = StandardScaler()\n","  data=scaler.fit_transform(data)\n","  unos=list(np.where(target==1)[0])\n","  unos=shuffle(unos,random_state=10)\n","\n","  ceros=list(np.where(target==0)[0])\n","  ceros=shuffle(ceros,random_state=10)\n","\n","  k_ceros=len(ceros)//numFolds\n","  k_unos=len(unos)//numFolds\n","\n","  fold_ceros=[ceros[k_ceros*i:k_ceros*(i+1)] for i in range(numFolds-1)]\n","  fold_unos=[unos[k_unos*i:k_unos*(i+1)] for i in range(numFolds-1)]\n","\n","  fold_ceros.append(ceros[k_ceros*(numFolds-1):])\n","  fold_unos.append(unos[k_unos*(numFolds-1):])\n","\n","  valid_ceros=fold_ceros[fold]\n","  valid_unos=fold_unos[fold]\n","\n","  label_fold_ceros=fold_ceros[(fold+1)%numFolds][:n_labeled]\n","  label_fold_unos=fold_unos[(fold+1)%numFolds][:n_labeled]\n","\n","  unlabeled_ceros=set()\n","  unlabeled_unos=set()\n","\n","  for i in range(numFolds):\n","    if i!=fold and i!=(fold+1)%numFolds:\n","      unlabeled_ceros=unlabeled_ceros.union(set(fold_ceros[i]))\n","      unlabeled_unos=unlabeled_unos.union(set(fold_unos[i]))\n","    elif i==(fold+1)%numFolds:\n","      unlabeled_ceros=unlabeled_ceros.union(set(fold_ceros[i][n_labeled:]))\n","      unlabeled_unos=unlabeled_unos.union(set(fold_unos[i][n_labeled:]))\n","\n","\n","  puntos_ceros_valid=np.array(data)[valid_ceros]\n","  puntos_unos_valid=np.array(data)[valid_unos]\n","\n","  puntos_ceros=np.array(data)[label_fold_ceros]\n","  puntos_unos=np.array(data)[label_fold_unos]\n","\n","  X_unlabeled_ceros=np.array(data)[list(unlabeled_ceros)]\n","  X_unlabeled_unos=np.array(data)[list(unlabeled_unos)]\n","\n","\n","  print(\"SUMMARY\")\n","  print(\"Train 0: \"+str(len(puntos_ceros)))\n","  print(\"Train 1: \"+str(len(puntos_unos)))\n","  print(\"Valid 0: \"+str(len(puntos_ceros_valid)))\n","  print(\"Valid 1: \"+str(len(puntos_unos_valid)))\n","  print(\"Unlabelled 0: \"+str(len(X_unlabeled_ceros)))\n","  print(\"Unlabelled 1: \"+str(len(X_unlabeled_unos)))\n","\n","  return (puntos_ceros,puntos_unos,X_unlabeled_ceros,X_unlabeled_unos,puntos_ceros_valid,puntos_unos_valid)"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","import scipy.spatial.distance as dist\n","from scipy.sparse.csgraph import minimum_spanning_tree\n","\n","def compute_Mf_0(X, Z, is_dist=False):\n","    \"\"\"Compute the matching induced by the inclusion X --> Z given by sending points from X, in order, to the first points from Z.\n","    We assume that coordinates of X and Z are given as numpy arrays, where the number of rows from Z is greater or equal to X.\n","    If is_dist is True, we assume that X and Z are given as distance matrices.\n","\n","    This returns a pair of lists with endpoints of intervals, that are representations of both barcodes, together with a matching between such lists given by a list of indices.\n","\"\"\"\n","    filtration_list_X, pairs_arr_X = mst_edge_filtration(X, is_dist=is_dist) # MST(X)\n","    filtration_list_Z, pairs_arr_Z = mst_edge_filtration(Z, is_dist=is_dist) # MST(Z)\n","    TMT_X_pairs = compute_tmt_pairs(filtration_list_X, pairs_arr_X)\n","    TMT_Z_pairs = compute_tmt_pairs(filtration_list_Z, pairs_arr_Z)\n","    indices_X_Z = np.max(TMT_Z_pairs, axis=1)<X.shape[0]\n","    TMT_X_Z_pairs = TMT_Z_pairs[indices_X_Z]\n","    indices_X_Z = np.nonzero(indices_X_Z)[0]\n","    FX = get_inclusion_matrix(TMT_X_pairs, TMT_X_Z_pairs) # Associated matrix\n","    matchingX = get_inclusion_matrix_pivots(FX, Z.shape[0]) # Matching in TMT_X_Z\n","    matching =[indices_X_Z[i] for i in matchingX] # Matching in all TMT_Z\n","    return filtration_list_X, filtration_list_Z, matching\n","\n","def read_csr_matrix(cs_matrix):\n","    \"\"\"Function to read output from minimum_spanning_tree and prepare it as a list of\n","    filtration values (in order) together with an array with the corresponding pairs.\n","    \"\"\"\n","    filtration_list = []\n","    edges = []\n","    entry_idx = 0\n","    for i, cummul_num_entries in enumerate(cs_matrix.indptr[1:]):\n","        while entry_idx < cummul_num_entries:\n","            edges.append((i, cs_matrix.indices[entry_idx]))\n","            filtration_list.append(cs_matrix.data[entry_idx])\n","            entry_idx+=1\n","    # Sort filtration values and pairs\n","    edges_arr = np.array(edges)\n","    np.argsort(filtration_list)\n","    sort_idx = np.argsort(filtration_list)\n","    filtration_list = np.array(filtration_list)[sort_idx].tolist()\n","    edges_arr = edges_arr[sort_idx]\n","    return filtration_list, edges_arr\n","\n","def mst_edge_filtration(points, is_dist=False):\n","    \"\"\"Returns the edges and filtration values for the Euclidean minimum spanning tree\n","    of a given point sample.\n","    This is a wrapper for the scipy minimum_spanning_tree function.\n","    \"\"\"\n","    if is_dist:\n","        mst = minimum_spanning_tree(points)\n","    else:\n","        mst = minimum_spanning_tree(dist.squareform(dist.pdist(points)))\n","    # We now read the compressed sparse row matrix\n","    return read_csr_matrix(mst)\n","\n","def compute_tmt_pairs(filtration_list, edges_arr, tolerance=10e-8):\n","    # Get proper merge tree pairs\n","    E_b = []\n","    C = np.array(list(range(edges_arr.shape[0]+1)))\n","    tmt_pairs_list = []\n","    for i, (b, edge) in enumerate(zip(filtration_list, edges_arr)):\n","        E_b.append(edge)\n","        # If the next filtration value is very close, we continue addin edges to E_b\n","        if i < len(filtration_list)-1:\n","            if np.abs(b - filtration_list[i+1]) < tolerance:\n","                continue\n","\n","        # We iterate over E_b, adding triplets to tmt_pairs_list following steps (i)-(v) from the article\n","        while(len(E_b)>0):\n","            # (i) we take the edge [i,j] from E_b such that min{C[i],C[j]} is smallest\n","            E_b_C_min = [np.min(C[edge]) for edge in E_b]\n","            idx = np.argmin(E_b_C_min)\n","            edge = E_b[idx]\n","            # (ii)\n","            M, m = np.max(C[edge]), np.min(C[edge])\n","            assert m < M\n","            # (iii)\n","            tmt_pairs_list.append([M,m])\n","            # (iv)\n","            C[C==M]=m\n","            # (v)\n","            del(E_b[idx])\n","        # end when E_b is empty\n","    # end computing tmt\n","    tmt_pairs_arr = np.array(tmt_pairs_list)\n","    return tmt_pairs_arr\n","\n","\n","def add_columns_mod_2(col1, col2):\n","    \"\"\" Given two lists of integers, which are sparse representations of a pair of vectors in Z mod 2, this funciton adds them and\n","    returns the result in the same input format.\n","    \"\"\"\n","    diff_1 = set(col1).difference(set(col2))\n","    diff_2 = set(col2).difference(set(col1))\n","    result = diff_1.union(diff_2)\n","    return list(result)\n","\n","\n","def get_inclusion_matrix(pairs_arr_X, pairs_arr_Z, subset_indices=[]):\n","    \"\"\" Given two pairs of arrays with the vertex merge pairs, this function returns the associated inclusion matrix.\n","    From the point of view of minimum spanning trees, the output matrix columns can be interpreted as the minimum paths that are needed to\n","    go through in MST(Z) in order to connect the endpoints from an edge in MST(X)\n","    \"\"\"\n","    # If subset indices are not specified, we assume that the indices of vertices from S correspond to the first #X vertices from Z\n","    if (len(subset_indices)==0):\n","        subset_indices = list(range(pairs_arr_X.shape[0]+1))\n","    pivot2column = [-1] + np.argsort(np.max(pairs_arr_Z, axis=1)).tolist()\n","    inclusion_matrix = []\n","    for col_X in pairs_arr_X:\n","        col_X = [subset_indices[i] for i in col_X]\n","        col_M = []\n","        while(len(col_X)>0):\n","            piv = np.max(col_X)\n","            col_M.append(pivot2column[piv])\n","            col_X = add_columns_mod_2(col_X, pairs_arr_Z[pivot2column[piv]])\n","        # end reducing column X\n","        col_M.sort()\n","        inclusion_matrix.append(col_M)\n","    return inclusion_matrix\n","\n","def get_inclusion_matrix_pivots(matrix_list, num_rows):\n","    \"\"\" Returns the pivots of a matrix given in list format\"\"\"\n","    pivots = []\n","    pivot2column = np.ones(num_rows, dtype=\"int\")*-1\n","    for i, column in enumerate(matrix_list):\n","        reduce_column = list(column)\n","        piv = np.max(reduce_column)\n","        while(pivot2column[piv]>-1):\n","            reduce_column = add_columns_mod_2(reduce_column, matrix_list[pivot2column[piv]])\n","            piv = np.max(reduce_column)\n","            # we assume that columns are never reduced to the 0 column\n","        pivots.append(piv)\n","        pivot2column[piv] = i\n","    # end getting pivots\n","    return pivots\n","\n","\n","def plot_matching_0(filt_X, filt_Z, matching, ax):\n","    \"\"\" Given two zero dimensional barcodes as well as a block function between them, this function plots the associated diagram\"\"\"\n","    # Plot matching barcode\n","    for i, Z_end in enumerate(filt_Z):\n","        if i in matching:\n","            X_end = filt_X[matching.index(i)]\n","            ax.add_patch(mpl.patches.Rectangle([0, i-0.2], Z_end, 0.4, color=\"navy\", zorder=2))\n","            ax.add_patch(mpl.patches.Rectangle([Z_end*0.9, i-0.2], X_end-Z_end, 0.4, color=\"orange\", zorder=1.9))\n","        else:\n","            ax.add_patch(mpl.patches.Rectangle([0, i-0.2], Z_end, 0.4, color=\"aquamarine\", zorder=2))\n","\n","    MAX_PLOT_RAD = max(np.max(filt_X), np.max(filt_Z))*1.1\n","    ax.set_xlim([-0.1*MAX_PLOT_RAD, MAX_PLOT_RAD*1.1])\n","    ax.set_ylim([-0.1*len(filt_X), len(filt_Z)])\n","    ax.set_frame_on(False)\n","    ax.set_yticks([])\n","#end plot_matching_0\n","\n","def plot_density_matrix(filt_X, filt_Z, matching, ax, nbins=5):\n","    endpoints_Z = np.array(filt_Z)[matching]\n","    differences = np.array([[a, b] for (a,b) in zip(filt_X, endpoints_Z)])\n","    ax.hist2d(differences[:,0], differences[:,1], bins=(nbins, nbins), cmap=plt.cm.jet)\n","    ax.set_xlabel('Ends in X')\n","    ax.set_ylabel('Ends in Z')\n","\n","def plot_density_matrix_percentage(filt_X, filt_Z, matching, ax, nbins=5):\n","    ends_X = np.array(filt_X)\n","    max_end = np.max(ends_X)\n","    ends_diff = ends_X - np.array(filt_Z)[matching]\n","    Diag_diff = np.vstack((ends_X, ends_diff)).transpose()\n","    hist = np.histogram2d(Diag_diff[:,1], Diag_diff[:,0], bins=nbins, range=[[0,max_end], [0,max_end]])[0]\n","    sum_cols = np.sum(hist, axis=0)\n","    sum_cols = np.maximum(sum_cols, 1)\n","    hist = np.divide(hist, sum_cols)\n","    hist=hist[-1::-1]\n","    ax.imshow(hist, extent=(0, max_end, 0, max_end))\n","    ax.set_xlabel('Differences of the bars (percent)')\n","    ax.set_ylabel('Length of the bars Z')\n","\n","def compute_matching_diagram(filt_X, filt_Z, matching, _tol=1e-5):\n","    pairs = []\n","    for i, a in enumerate(filt_X):\n","        b = filt_Z[matching[i]]\n","        pairs.append((a, b))\n","    # end for\n","    multiplicities = []\n","    pairs_copy = list(pairs)\n","    old_pair = pairs_copy.pop()\n","    pairs = [old_pair] # create new pairs list with non-repeating entries\n","    multiplicities.append(1)\n","    # First compute matched pairs and their multiplicities\n","    while len(pairs_copy)>0:\n","        pair = pairs_copy.pop()\n","        if np.all(np.abs(np.array(pair)-np.array(old_pair)) < _tol):\n","            multiplicities[-1]+=1\n","        else:\n","            multiplicities.append(1)\n","            pairs.append(pair)\n","            old_pair = pair\n","        # end checking if pair similar\n","    # end while\n","    # Next compute right infinity points and their multiplicities\n","    unmatched_idx = [j for j in range(len(filt_Z)) if j not in matching]\n","    if len(unmatched_idx)>0:\n","        b = filt_Z[unmatched_idx.pop()]\n","        pairs.append((np.inf, b))\n","        multiplicities.append(1)\n","        while len(unmatched_idx)>0:\n","            prev_b = b\n","            b = filt_Z[unmatched_idx.pop()]\n","            if (np.abs(b-prev_b)<_tol):\n","                multiplicities[-1]+=1\n","            else:\n","                pairs.append((np.inf, b))\n","                multiplicities.append(1)\n","            # end checking same endpoint\n","        # iterate over unmatched intervals\n","    # only if some intervals are unmatched\n","    return np.array(pairs), multiplicities\n","\n","\n","def plot_matching_diagram(pairs, ax, colorpt=\"black\", marker=\"o\", size=15, hmax=None):\n","    fin_pairs = pairs[pairs[:,0]<np.inf]\n","    if hmax is None:\n","        max_x = max(np.max(fin_pairs), np.max(pairs[:,1]))\n","        lim_x = max_x*1.3\n","        infty_x = max_x*1.1\n","    else:\n","        max_x, lim_x, infty_x = hmax, hmax*1.3, hmax*1.1\n","    # end if-else loop\n","    ax.plot([0, lim_x], [0, lim_x], c=\"gray\", linewidth=1, zorder=1)\n","    ax.plot([infty_x, infty_x], [0, lim_x], c=\"blue\", linewidth=1, zorder=1)\n","    ax.scatter(fin_pairs[:,0], fin_pairs[:,1], color=colorpt, s=size, marker=marker, zorder=2)\n","    inf_points = pairs[pairs[:,0]==np.inf]\n","    ax.scatter(np.ones(len(inf_points))*infty_x, inf_points[:,1], color=colorpt, s=size, marker=marker, zorder=2)\n","    ax.text(infty_x*1.02, infty_x*1.1, \"∞\", fontsize=15, color=\"blue\")\n","    ax.scatter([infty_x], [infty_x], color=colorpt, s=size, marker=marker, zorder=2)\n","    # Adjust spines\n","    ax.spines[[\"top\", \"right\"]].set_visible(False)\n","    ax.spines[[\"bottom\",\"left\"]].set_position(\"zero\")\n","    # adjust margins\n","    ax.set_xlim([0,lim_x])\n","    ax.set_ylim([0,lim_x])\n","\n","def plot_density_matching_diagram(D_f_rep, coker_f, savepath, nbins=5, cmap=\"jet\", show_colorbar=False):\n","    ### First, create figure with two axes usin gridspec\n","    gs = mpl.gridspec.GridSpec(1,2, width_ratios=[nbins,1])\n","    fig = plt.figure(figsize=(4,4))\n","    ax = [fig.add_subplot(gs[0,i]) for i in range(2)]\n","    ### Next, let us read the information from the matching diagram and plot it\n","    fin_D_f = D_f_rep[D_f_rep[:,0]<np.inf]\n","    lim_x = 1.2*max(np.max(fin_D_f), np.max(D_f_rep[:,1]))\n","    hist_fin_D_f = np.histogram2d(fin_D_f[:,1], fin_D_f[:,0], bins=nbins, range=[[0,lim_x], [0,lim_x]])[0]\n","    hist_coker_f = np.histogram2d(np.zeros(len(coker_f)), coker_f, bins=[1,nbins], range=[[0,lim_x*0.1], [0,lim_x]])[0]\n","    vmax = max(np.max(hist_fin_D_f), np.max(hist_coker_f))\n","    ax[0].imshow(hist_fin_D_f, cmap=cmap, vmin=0, vmax=vmax, origin=\"lower\", extent=(0,lim_x,0,lim_x))\n","    image = ax[1].imshow(hist_coker_f.transpose(), cmap=cmap, vmin=0, vmax=vmax, origin=\"lower\", extent=(0,lim_x/nbins,0,lim_x))\n","    ax[1].set_yticks([])\n","    ax[1].set_xticks([])\n","    # Draw labels\n","    ax[0].set_xlabel('Ends in X')\n","    ax[0].set_ylabel('Ends in Z')\n","    ax[1].set_ylabel('Coker(f)')\n","    # Colorbar\n","    if show_colorbar:\n","        plt.colorbar(mappable=image, ax=ax, orientation=\"horizontal\", location=\"top\")\n","    ### Save figure\n","    plt.savefig(savepath)\n","\n","def plot_matching_0(filt_X, filt_Z, matching, ax):\n","    \"\"\" Given two zero dimensional barcode endpoint lists as well as a block function between them, this function plots the associated diagram\"\"\"\n","    # Plot matching barcode\n","    for i, Z_end in enumerate(filt_Z):\n","        if i in matching:\n","            X_end = filt_X[matching.index(i)]\n","            ax.add_patch(mpl.patches.Rectangle([0, i-0.2], Z_end, 0.4, color=\"navy\", zorder=2))\n","            ax.add_patch(mpl.patches.Rectangle([Z_end*0.9, i-0.2], X_end-Z_end, 0.4, color=\"orange\", zorder=1.9))\n","        else:\n","            ax.add_patch(mpl.patches.Rectangle([0, i-0.2], Z_end, 0.4, color=\"aquamarine\", zorder=2))\n","\n","    MAX_PLOT_RAD = max(np.max(filt_X), np.max(filt_Z))*1.1\n","    ax.set_xlim([-0.1*MAX_PLOT_RAD, MAX_PLOT_RAD*1.1])\n","    ax.set_ylim([-0.1*len(filt_Z), len(filt_Z)])\n","    ax.set_frame_on(False)\n","    ax.set_yticks([])\n","#end plot_matching_0\n","\n","### Random Circle Creation\n","def sampled_circle(r, R, n, RandGen):\n","    assert r<=R\n","    radii = RandGen.uniform(r,R,n)\n","    angles = RandGen.uniform(0,2*np.pi,n)\n","    return np.vstack((np.cos(angles)*radii, np.sin(angles)*radii)).transpose()"],"metadata":{"id":"40c2pSx8BiZR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calc_dist(punto,conjunto):\n","  z=np.append(conjunto,np.expand_dims(punto,axis=0),axis=0)\n","  a,b,c=compute_Mf_0(conjunto,z)\n","  D_f, multiplicities = compute_matching_diagram(a, b, c, _tol=1e-5)\n","  D_f_rep = []\n","  for i, pair in enumerate(D_f):\n","      for j in range(multiplicities[i]):\n","          D_f_rep += list(pair)\n","\n","  D_f_rep = np.array(D_f_rep).reshape(-1,2)\n","\n","  fin_D_f = D_f_rep[D_f_rep[:,0]<np.inf]\n","\n","  coker_f = D_f[D_f[:,0]==np.inf][:,1]\n","\n","  distancia=np.sum(coker_f)\n","  return distancia"],"metadata":{"id":"5eyqqrfbBm9l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def analizar_punto_rocio(punto,puntos_ceros,puntos_unos,th=0):\n","\n","  d0=calc_dist(punto,puntos_ceros)\n","\n","  d1=calc_dist(punto,puntos_unos)\n","\n","  d=d0+d1\n","\n","\n","  if max(d0/d,d1/d)<th:\n","    clase=-1\n","  else:\n","    if d0>d1:\n","      clase=1\n","    else:\n","      clase=0\n","  return clase"],"metadata":{"id":"hbDbQdUuByxe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def analizar_puntos_rocio(data,target,func,th=0,reduccion=False,dim=0,fold=0):\n","  (puntos_ceros,puntos_unos,X_unlabeled_ceros,X_unlabeled_unos,X_unlabeled_ceros_valid,X_unlabeled_unos_valid)=preparar_dataset(data,target,fold=fold)\n","  embedding=data\n","  if reduccion==True:\n","    embedding=umap.UMAP(random_state=75).fit_transform(data)\n","  (puntos_ceros_umap,puntos_unos_umap,X_unlabeled_ceros_umap,X_unlabeled_unos_umap,X_unlabeled_ceros_valid_umap,X_unlabeled_unos_valid_umap)=preparar_dataset(embedding,target,fold=fold)\n","\n","\n","  bien=0\n","  mal=0\n","  dudoso=0\n","\n","  puntos_ceros_final=puntos_ceros.tolist()\n","  puntos_unos_final=puntos_unos.tolist()\n","  puntos_dudosos_final=[]\n","\n","  for i,punto in enumerate(X_unlabeled_unos_umap):\n","    clase=func(punto,puntos_ceros_umap,puntos_unos_umap,th)\n","    if clase==1:\n","      bien=bien+1\n","      puntos_unos_final.append(X_unlabeled_unos[i])\n","    elif clase==0:\n","      mal=mal+1\n","      puntos_ceros_final.append(X_unlabeled_unos[i])\n","    else:\n","      dudoso=dudoso+1\n","      puntos_dudosos_final.append(X_unlabeled_unos[i])\n","\n","\n","\n","  for i,punto in enumerate(X_unlabeled_ceros_umap):\n","    clase=func(punto,puntos_ceros_umap,puntos_unos_umap,th)\n","    if clase==1:\n","      mal=mal+1\n","      puntos_unos_final.append(X_unlabeled_ceros[i])\n","    elif clase==0:\n","      bien=bien+1\n","      puntos_ceros_final.append(X_unlabeled_ceros[i])\n","    else:\n","      dudoso=dudoso+1\n","      puntos_dudosos_final.append(X_unlabeled_ceros[i])\n","\n","  metrics_svm,metrics_rf=comprobar_accuracy(np.array(puntos_ceros_final),np.array(puntos_unos_final),X_unlabeled_ceros_valid,X_unlabeled_unos_valid)\n","\n","  return (bien, mal,dudoso,np.array(puntos_ceros_final),np.array(puntos_unos_final),np.array(puntos_dudosos_final),metrics_svm,metrics_rf)"],"metadata":{"id":"0GFGVg9uC-AW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TZIfw9TKDSmS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgE3OlOOby00"},"outputs":[],"source":["def analizar_punto(punto,puntos_ceros,puntos_unos,dgms_ceros,dgms_unos,th=0,dim=0):\n","  dgms_ceros_mod = ripser(np.array([punto.tolist()]+puntos_ceros.tolist()))['dgms'][dim]\n","  distance_bottleneck_cero = persim.bottleneck(dgms_ceros_mod, dgms_ceros, matching=False)\n","\n","  dgms_unos_mod = ripser(np.array([punto.tolist()]+puntos_unos.tolist()))['dgms'][dim]\n","  distance_bottleneck_uno = persim.bottleneck(dgms_unos_mod, dgms_unos, matching=False)\n","  clase=-1\n","\n","  if distance_bottleneck_cero>distance_bottleneck_uno:\n","    clase=1\n","  else:\n","    clase=0\n","  return clase"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZAt2LnJvnPDF"},"outputs":[],"source":["def analizar_punto_th(punto,puntos_ceros,puntos_unos,dgms_ceros,dgms_unos,th=0.8,dim=0):\n","  dgms_ceros_mod = ripser(np.array([punto.tolist()]+puntos_ceros.tolist()))['dgms'][dim]\n","  distance_bottleneck_cero = persim.bottleneck(dgms_ceros_mod, dgms_ceros, matching=False)\n","\n","  dgms_unos_mod = ripser(np.array([punto.tolist()]+puntos_unos.tolist()))['dgms'][dim]\n","  distance_bottleneck_uno = persim.bottleneck(dgms_unos_mod, dgms_unos, matching=False)\n","\n","  distancia=distance_bottleneck_cero+distance_bottleneck_uno\n","\n","  if max(distance_bottleneck_cero/distancia,distance_bottleneck_uno/distancia)<th:\n","    clase=-1\n","  elif distance_bottleneck_cero>distance_bottleneck_uno:\n","    clase=1\n","  else:\n","    clase=0\n","  return clase"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8d4Ajzj3fuWT"},"outputs":[],"source":["def analizar_punto_Wasserstein(punto,puntos_ceros,puntos_unos,dgms_ceros,dgms_unos,th=0,dim=0):\n","  dgms_ceros_mod = ripser(np.array([punto.tolist()]+puntos_ceros.tolist()))['dgms'][dim]\n","  distance_bottleneck_cero = persim.wasserstein(dgms_ceros_mod, dgms_ceros, matching=False)\n","\n","  dgms_unos_mod = ripser(np.array([punto.tolist()]+puntos_unos.tolist()))['dgms'][dim]\n","  distance_bottleneck_uno = persim.wasserstein(dgms_unos_mod, dgms_unos, matching=False)\n","  clase=-1\n","\n","  if distance_bottleneck_cero>distance_bottleneck_uno:\n","    clase=1\n","  else:\n","    clase=0\n","  return clase"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V5V-oeUhnU16"},"outputs":[],"source":["def analizar_punto_Wasserstein_th(punto,puntos_ceros,puntos_unos,dgms_ceros,dgms_unos,th=0.8,dim=0):\n","  dgms_ceros_mod = ripser(np.array([punto.tolist()]+puntos_ceros.tolist()))['dgms'][dim]\n","  distance_bottleneck_cero = persim.wasserstein(dgms_ceros_mod, dgms_ceros, matching=False)\n","\n","  dgms_unos_mod = ripser(np.array([punto.tolist()]+puntos_unos.tolist()))['dgms'][dim]\n","  distance_bottleneck_uno = persim.wasserstein(dgms_unos_mod, dgms_unos, matching=False)\n","\n","  distancia=distance_bottleneck_cero+distance_bottleneck_uno\n","\n","  if max(distance_bottleneck_cero/distancia,distance_bottleneck_uno/distancia)<th:\n","    clase=-1\n","  elif distance_bottleneck_cero>distance_bottleneck_uno:\n","    clase=1\n","  else:\n","    clase=0\n","  return clase"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xr8FF7QaNyRA"},"outputs":[],"source":["def analizar_puntos(data,target,func,th=0,reduccion=False,dim=0,fold=0):\n","  (puntos_ceros,puntos_unos,X_unlabeled_ceros,X_unlabeled_unos,X_unlabeled_ceros_valid,X_unlabeled_unos_valid)=preparar_dataset(data,target,fold=fold)\n","  embedding=data\n","  if reduccion==True:\n","    embedding=umap.UMAP(random_state=75).fit_transform(data)\n","  (puntos_ceros_umap,puntos_unos_umap,X_unlabeled_ceros_umap,X_unlabeled_unos_umap,X_unlabeled_ceros_valid_umap,X_unlabeled_unos_valid_umap)=preparar_dataset(embedding,target,fold=fold)\n","\n","\n","  bien=0\n","  mal=0\n","  dudoso=0\n","\n","  puntos_ceros_final=puntos_ceros.tolist()\n","  puntos_unos_final=puntos_unos.tolist()\n","  puntos_dudosos_final=[]\n","\n","  dgms_ceros = ripser(puntos_ceros_umap)['dgms'][dim]\n","  dgms_unos = ripser(puntos_unos_umap)['dgms'][dim]\n","  for i,punto in enumerate(X_unlabeled_unos_umap):\n","    clase=func(punto,puntos_ceros_umap,puntos_unos_umap,dgms_ceros,dgms_unos,th,dim)\n","    if clase==1:\n","      bien=bien+1\n","      puntos_unos_final.append(X_unlabeled_unos[i])\n","    elif clase==0:\n","      mal=mal+1\n","      puntos_ceros_final.append(X_unlabeled_unos[i])\n","    else:\n","      dudoso=dudoso+1\n","      puntos_dudosos_final.append(X_unlabeled_unos[i])\n","\n","\n","\n","  for i,punto in enumerate(X_unlabeled_ceros_umap):\n","    clase=func(punto,puntos_ceros_umap,puntos_unos_umap,dgms_ceros,dgms_unos,th,dim)\n","    if clase==1:\n","      mal=mal+1\n","      puntos_unos_final.append(X_unlabeled_ceros[i])\n","    elif clase==0:\n","      bien=bien+1\n","      puntos_ceros_final.append(X_unlabeled_ceros[i])\n","    else:\n","      dudoso=dudoso+1\n","      puntos_dudosos_final.append(X_unlabeled_ceros[i])\n","\n","  metrics_svm,metrics_rf=comprobar_accuracy(np.array(puntos_ceros_final),np.array(puntos_unos_final),X_unlabeled_ceros_valid,X_unlabeled_unos_valid)\n","\n","  return (bien, mal,dudoso,np.array(puntos_ceros_final),np.array(puntos_unos_final),np.array(puntos_dudosos_final),metrics_svm,metrics_rf)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ipmdHoF5nbnT"},"outputs":[],"source":["def resumen(bien,mal,dudosos):\n","  print('-----------------RESUMEN------------------')\n","  print('Correct '+str(bien))\n","  print('Wrong '+str(mal))\n","  print('Unlabelled '+str(dudosos))\n","  print('')\n","  acc=0\n","  if bien+mal!=0:\n","    print('Correct percentage '+str(bien/(bien+mal)))\n","    acc=bien/(bien+mal)\n","  else:\n","    print('Correct percentage 0')\n","  print('Labelled percentage '+str((bien+mal)/(bien+mal+dudosos)))\n","  anotados=(bien+mal)/(bien+mal+dudosos)\n","  return acc,anotados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qUJ5-HGBKAIs"},"outputs":[],"source":["from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","\n","\n","def comprobar_accuracy(puntos_ceros_final,puntos_unos_final,X_unlabeled_ceros_valid,X_unlabeled_unos_valid):\n","    datos=np.concatenate((puntos_ceros_final,puntos_unos_final),axis=0)\n","    labels=np.concatenate((np.zeros(puntos_ceros_final.shape[0]),np.ones(puntos_unos_final.shape[0])))\n","\n","    modelSVMLineal = SVC(kernel=\"linear\",probability=True,random_state=90,max_iter=10000)\n","    modelSVMLineal.fit(datos, labels)\n","\n","    predicted_ceros=np.array(modelSVMLineal.predict(X_unlabeled_ceros_valid))\n","    target_ceros=np.zeros_like(predicted_ceros)\n","\n","\n","\n","    predicted_unos=np.array(modelSVMLineal.predict(X_unlabeled_unos_valid))\n","    target_unos=np.ones_like(predicted_unos)\n","\n","\n","    predicted=np.concatenate((predicted_ceros,predicted_unos))\n","    target=np.concatenate((target_ceros,target_unos))\n","\n","    acc_svm=accuracy_score(target,predicted)\n","    pre_svm=precision_score(target,predicted)\n","    f1_svm=f1_score(target,predicted)\n","    rec_svm=recall_score(target,predicted)\n","\n","\n","\n","    print(\"--------------Classifier SVM--------------\")\n","    print(\"Accuracy: \"+str(acc_svm))\n","    print(\"Precision: \"+str(pre_svm))\n","    print(\"Recall: \"+str(rec_svm))\n","    print(\"F1: \"+str(f1_svm))\n","    print(\"\")\n","\n","\n","\n","\n","    modelRandomForest = RandomForestClassifier(random_state=90)\n","    modelRandomForest.fit(datos, labels)\n","\n","\n","\n","\n","    predicted_ceros=np.array(modelRandomForest.predict(X_unlabeled_ceros_valid))\n","    target_ceros=np.zeros_like(predicted_ceros)\n","\n","\n","    predicted_unos=np.array(modelRandomForest.predict(X_unlabeled_unos_valid))\n","    target_unos=np.ones_like(predicted_unos)\n","\n","\n","\n","    predicted=np.concatenate((predicted_ceros,predicted_unos))\n","    target=np.concatenate((target_ceros,target_unos))\n","\n","    acc_rf=accuracy_score(target,predicted)\n","    pre_rf=precision_score(target,predicted)\n","    f1_rf=f1_score(target,predicted)\n","    rec_rf=recall_score(target,predicted)\n","\n","    print(\"-------------- Classifier Random Forest--------------\")\n","    print(\"Accuracy: \"+str(acc_svm))\n","    print(\"Precision: \"+str(pre_svm))\n","    print(\"Recall: \"+str(rec_svm))\n","    print(\"F1: \"+str(f1_svm))\n","    print(\"\")\n","    return (acc_svm,pre_svm,rec_svm,f1_svm),(acc_rf,pre_rf,rec_rf,f1_rf)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQnr4viizF84"},"outputs":[],"source":["def label_prop(data,target,fold=0,th=0):\n","  (puntos_ceros,puntos_unos,X_unlabeled_ceros,X_unlabeled_unos,puntos_ceros_valid,puntos_unos_valid)=preparar_dataset(data,target,fold=fold)\n","  datos=np.concatenate((puntos_ceros,puntos_unos),axis=0)\n","  labels=np.concatenate((np.zeros(puntos_ceros.shape[0]),np.ones(puntos_unos.shape[0])))\n","\n","  label_prop_model = LabelPropagation(kernel='knn')\n","  label_prop_model.fit(datos, labels)\n","\n","###################ZEROS#################\n","  pred_ceros=label_prop_model.predict_proba(X_unlabeled_ceros)\n","\n","  prob_ceros=np.max(pred_ceros,axis=1)\n","  clases_ceros=np.argmax(pred_ceros,axis=1)\n","\n","  ind_dudosos_ceros=np.where(prob_ceros<th)[0]\n","  ind_no_dudosos_ceros=np.where(prob_ceros>=th)[0]\n","\n","\n","  unos=np.where(clases_ceros==1)[0]\n","\n","  ceros=np.where(clases_ceros==0)[0]\n","\n","\n","  unos=unos[np.isin(unos,ind_no_dudosos_ceros)]\n","  mal=unos.shape[0]\n","  ceros=ceros[np.isin(ceros,ind_no_dudosos_ceros)]\n","  bien=ceros.shape[0]\n","\n","\n","  datos_uno=np.array(X_unlabeled_ceros)[unos]\n","  datos_cero=np.array(X_unlabeled_ceros)[ceros]\n","\n","  nuevos_puntos_cero=np.asarray(list(puntos_ceros)+list(datos_cero))\n","  nuevos_puntos_uno=np.asarray(list(puntos_unos)+list(datos_uno))\n","\n","  dudoso_cero=np.array(X_unlabeled_ceros)[ind_dudosos_ceros]\n","  dudoso=ind_dudosos_ceros.shape[0]\n","\n","\n","######################ONES#############################################\n","  pred_unos=label_prop_model.predict_proba(X_unlabeled_unos)\n","\n","  prob_unos=np.max(pred_unos,axis=1)\n","  clases_unos=np.argmax(pred_unos,axis=1)\n","\n","  ind_dudosos_unos=np.where(prob_unos<th)[0]\n","  ind_no_dudosos_unos=np.where(prob_unos>=th)[0]\n","\n","\n","  unos=np.where(clases_unos==1)[0]\n","\n","  ceros=np.where(clases_unos==0)[0]\n","\n","\n","  unos=unos[np.isin(unos,ind_no_dudosos_unos)]\n","  bien+=unos.shape[0]\n","  ceros=ceros[np.isin(ceros,ind_no_dudosos_unos)]\n","  mal+=ceros.shape[0]\n","\n","\n","  datos_uno=np.array(X_unlabeled_unos)[unos]\n","  datos_cero=np.array(X_unlabeled_unos)[ceros]\n","\n","\n","  nuevos_puntos_cero=np.asarray(list(nuevos_puntos_cero)+list(datos_cero))\n","  nuevos_puntos_uno=np.asarray(list(nuevos_puntos_uno)+list(datos_uno))\n","\n","  dudoso_uno=np.array(X_unlabeled_unos)[ind_dudosos_unos]\n","\n","  dudosos=np.concatenate((dudoso_cero,dudoso_uno))\n","  dudoso+=ind_dudosos_unos.shape[0]\n","\n","  metrics_svm,metrics_rf=comprobar_accuracy(nuevos_puntos_cero,nuevos_puntos_uno,puntos_ceros_valid,puntos_unos_valid)\n","\n","  return (bien, mal,dudoso, nuevos_puntos_cero, nuevos_puntos_uno, dudoso,metrics_svm,metrics_rf)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gSCjbUml1J4Q"},"outputs":[],"source":["path=''\n","with open(path+'BCI.csv', 'w', newline='') as csvfile:\n","  spamwriter = csv.writer(csvfile)\n","  spamwriter.writerow(['Method','acc_anot_1','%lab_1','svm_1_acc','svm_1_pre','svm_1_rec','svm_1_f1','rf_1_acc','rf_1_pre','rf_1_rec','rf_1_f1','acc_anot_2','%lab_2','svm_2_acc','svm_2_pre','svm_2_rec','svm_2_f1','rf_2_acc','rf_2_pre','rf_2_rec','rf_2_f1','acc_anot_3','%lab_3','svm_3_acc','svm_3_pre','svm_3_rec','svm_3_f1','rf_3_acc','rf_3_pre','rf_3_rec','rf_3_f1','acc_anot_4','%lab_4','svm_4_acc','svm_4_pre','svm_4_rec','svm_4_f1','rf_4_acc','rf_4_pre','rf_4_rec','rf_4_f1','acc_anot_5','%lab_5','svm_5_acc','svm_5_pre','svm_5_rec','svm_5_f1','rf_5_acc','rf_5_pre','rf_5_rec','rf_5_f1'])"]},{"cell_type":"code","source":["k=5"],"metadata":{"id":"UiZuOebtDdIU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fila=['Rocio_00']\n","for i in range(k):\n","  print(\"-------------------ITERATION \"+str(i)+\"---------------------\")\n","  (data,target) = load_prima()\n","  (bien,mal,dudoso,pcero,puno,pdudoso,acc_svm,acc_rf)=analizar_puntos_rocio(data,target,analizar_punto_rocio,fold=i)\n","  acc,anotados=resumen(bien,mal,dudoso)\n","  print(\"\")\n","  print(\"\")\n","  fila.append(acc)\n","  fila.append(anotados)\n","  fila.append(acc_svm[0])\n","  fila.append(acc_svm[1])\n","  fila.append(acc_svm[2])\n","  fila.append(acc_svm[3])\n","  fila.append(acc_rf[0])\n","  fila.append(acc_rf[1])\n","  fila.append(acc_rf[2])\n","  fila.append(acc_rf[3])\n","with open(path+'BCI.csv', 'a', newline='') as csvfile:\n","  spamwriter = csv.writer(csvfile)\n","  spamwriter.writerow(fila)"],"metadata":{"id":"OTmJjsWGDdFg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fila=['Rocio_08']\n","for i in range(k):\n","  print(\"-------------------ITERATION \"+str(i)+\"---------------------\")\n","  (data,target) = load_prima()\n","  (bien,mal,dudoso,pcero,puno,pdudoso,acc_svm,acc_rf)=analizar_puntos_rocio(data,target,analizar_punto_rocio,th=0.8,fold=i)\n","  acc,anotados=resumen(bien,mal,dudoso)\n","  print(\"\")\n","  print(\"\")\n","  fila.append(acc)\n","  fila.append(anotados)\n","  fila.append(acc_svm[0])\n","  fila.append(acc_svm[1])\n","  fila.append(acc_svm[2])\n","  fila.append(acc_svm[3])\n","  fila.append(acc_rf[0])\n","  fila.append(acc_rf[1])\n","  fila.append(acc_rf[2])\n","  fila.append(acc_rf[3])\n","with open(path+'BCI.csv', 'a', newline='') as csvfile:\n","  spamwriter = csv.writer(csvfile)\n","  spamwriter.writerow(fila)"],"metadata":{"id":"-OMdJQIYDdC5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fila=['Rocio_06']\n","for i in range(k):\n","  print(\"-------------------ITERATION \"+str(i)+\"---------------------\")\n","  (data,target) = load_prima()\n","  (bien,mal,dudoso,pcero,puno,pdudoso,acc_svm,acc_rf)=analizar_puntos_rocio(data,target,analizar_punto_rocio,th=0.6,fold=i)\n","  acc,anotados=resumen(bien,mal,dudoso)\n","  print(\"\")\n","  print(\"\")\n","  fila.append(acc)\n","  fila.append(anotados)\n","  fila.append(acc_svm[0])\n","  fila.append(acc_svm[1])\n","  fila.append(acc_svm[2])\n","  fila.append(acc_svm[3])\n","  fila.append(acc_rf[0])\n","  fila.append(acc_rf[1])\n","  fila.append(acc_rf[2])\n","  fila.append(acc_rf[3])\n","with open(path+'BCI.csv', 'a', newline='') as csvfile:\n","  spamwriter = csv.writer(csvfile)\n","  spamwriter.writerow(fila)"],"metadata":{"id":"oWbbTDeoLHWD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zNU2C10bDcr4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["k=5"],"metadata":{"id":"YwAA0dNGFMKF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"53IBiMpixyn-"},"source":["# Bottleneck threshold"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sXYO6QHJ3rbE"},"outputs":[],"source":["fila=['Bottleneck_08']\n","for i in range(k):\n","  (data,target) = load_prima()\n","  (bien,mal,dudoso,pcero,puno,pdudoso,acc_svm,acc_rf)=analizar_puntos(data,target,analizar_punto_th,0.8,fold=i)\n","  acc,anotados=resumen(bien,mal,dudoso)\n","  print(\"\")\n","  print(\"\")\n","  fila.append(acc)\n","  fila.append(anotados)\n","  fila.append(acc_svm[0])\n","  fila.append(acc_svm[1])\n","  fila.append(acc_svm[2])\n","  fila.append(acc_svm[3])\n","  fila.append(acc_rf[0])\n","  fila.append(acc_rf[1])\n","  fila.append(acc_rf[2])\n","  fila.append(acc_rf[3])\n","with open(path+'BCI.csv', 'a', newline='') as csvfile:\n","  spamwriter = csv.writer(csvfile)\n","  spamwriter.writerow(fila)"]},{"cell_type":"markdown","metadata":{"id":"YADuXjfTx7du"},"source":["# Wasserstein threshold"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awGORjGuLXFc"},"outputs":[],"source":["fila=['Wasserstein_08']\n","for i in range(k):\n","  (data,target) = load_prima()\n","  (bien,mal,dudoso,pcero,puno,pdudoso,acc_svm,acc_rf)=analizar_puntos(data,target,analizar_punto_Wasserstein_th,0.8,fold=i)\n","  acc,anotados=resumen(bien,mal,dudoso)\n","  print(\"\")\n","  print(\"\")\n","  fila.append(acc)\n","  fila.append(anotados)\n","  fila.append(acc_svm[0])\n","  fila.append(acc_svm[1])\n","  fila.append(acc_svm[2])\n","  fila.append(acc_svm[3])\n","  fila.append(acc_rf[0])\n","  fila.append(acc_rf[1])\n","  fila.append(acc_rf[2])\n","  fila.append(acc_rf[3])\n","with open(path+'BCI.csv', 'a', newline='') as csvfile:\n","  spamwriter = csv.writer(csvfile)\n","  spamwriter.writerow(fila)"]},{"cell_type":"markdown","metadata":{"id":"slekjgj3ESb6"},"source":["# LabelPropagation 0.8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zduqiiiqEScO"},"outputs":[],"source":["fila=['LabelPropagation_08']\n","for i in range(k):\n","  (data,target) = load_prima()\n","  (bien,mal,dudoso,pcero,puno,pdudoso,acc_svm,acc_rf)=label_prop(data,target,fold=i,th=0.8)\n","  acc,anotados=resumen(bien,mal,dudoso)\n","  print(\"\")\n","  print(\"\")\n","  fila.append(acc)\n","  fila.append(anotados)\n","  fila.append(acc_svm[0])\n","  fila.append(acc_svm[1])\n","  fila.append(acc_svm[2])\n","  fila.append(acc_svm[3])\n","  fila.append(acc_rf[0])\n","  fila.append(acc_rf[1])\n","  fila.append(acc_rf[2])\n","  fila.append(acc_rf[3])\n","with open(path+'BCI.csv', 'a', newline='') as csvfile:\n","  spamwriter = csv.writer(csvfile)\n","  spamwriter.writerow(fila)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPNs62ASIqiY3NZpznodcaI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}